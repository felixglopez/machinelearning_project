---
title: "final project machine learning"
author: "Felix G Lopez"
date: "`r Sys.Date()`"
output: html_document
---
### Project Assignment for Practical Machine Learning

#### A course in the Johns Hopkins Coursera Data Science specialization


#### Summary

This report present an analysis that corresponds to the Project Assignment for the Practical Machine Learning course of the John Hopkins Data Science Specialization at Coursera. The project uses data from the Weight Lifting Exercises (WLE) Dataset (see http://groupware.les.inf.puc-rio.br/har and also the References section below.) 

According to the WLE website, six participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions, identified as classes A, B, C, D and E. Class A corresponds to a correct execution of the exercise, and the remaining five classes identify common mistakes in this weight lifting exercise. Several sensors were used to collect data about the quality of the exercise execution. The goal of this project is to obtain a prediction algorithm that takes such a set of sensor readings and correctly predicts the corresponding class (A to E).

The following analysis uses a random forest prediction algorithm to accomplish this task, after data cleaning. The results of the analysis confirm that the model provided by this algorithm achieves a high prediction accuracy (as indicated by several prediction quality indicators).

#### Discussion and Code for the Analysis.

Data File Loading and Initial Data Exploration.

The project assignment includes two data files (in csv format), that can be downloaded from these links:

```{r}
#dowloading training dataset
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileUrl, destfile = "pml-training.csv")
pml_training <- read.table("pml-training.csv", 
                               header = TRUE, sep = ",", 
                               na.strings = c("NA", "#DIV/0!"))
```

```{r}
#downloading testing dataset
file2Url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(file2Url, destfile = "pml-testing.csv")
pml_testing <- read.csv("pml-testing.csv")
```

The pml-training.csv file contains both sensor data and execution type data, but the pml-testing.csv file does not contain execution type data. As an additional part of the assignment, we have to use the prediction algorithm trained on the data from the pml-testing.csv file, in order to predict the execution type for the data in the pml-testing.csv file.

In this assignment there is no codebook for the data files. However, relevant information can be obtained from the sources cited, here:

[https://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har]


In particular, we know that four types of sensors were used in the experiment, and we will see below that this is reflected in the names of many of the variables in the data set.

First I read the pml-training.csv file into R. An initial inspection of the data file (using e.g. a text editor or a spreadsheet program) shows that:

The data columns in the file are separated by commas. There are many missing values. These missing values come in two versions: the usual NA value, but also as values of the form “#DIV/0!” (this is probably the result of an attempt to divide by zero in a spreadsheet).

The header line contains the names of the variables in the data set.
The first column is not really a variable, it just contains the row number.
Taking all that into account, we read the csv into a data frame in R as follows:

`{r}dim(pml_training_data)`
## [1] 19622   160

As you can see, the data frame has 19622 rows (observations) and 160 columns (variables). Most of the variables (152 out of 160) correspond to sensor readings for one of the four sensors. Those sensor-reading variable names (columns 8 to 159) include one of the following strings to identify the corresponding sensor:

_belt   _arm   _dumbbell   _forearm

The last column in the data frame (column 160) contains the values A to E of the classe variable that indicates the execution type of the exercise.

Finally, the first seven columns contain:

column 1: the row index (not really a variable).
column 2: the user_name variable; that is, the name of the person performing the exercise.
columns 3 to 7: variables related to the time window for that particular sensor reading. See Section 5.1 of the paper in the references for more details on these variables.

Restricting the Variables to Sensor-related Ones.
Thus, the data in the first seven columns are not sensor readings. For the prediction purposes of this analysis, we will remove the data in those columns from the data frame (using grep to select the sensor-related columns).

```{r}
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(pml_training_data))
  length(sensorColumns)
## [1] 152
  data = pml_training_data[, c(sensorColumns,160)]
  dim(data)
## [1] 19622   153
```
  
See the Notes section below for further discussion of this choice of variables.

#### Handling NA Values.
The selected sensor data columns still include many variables whose values are NA for almost all observations. To remove those variables we do the following:

```{r}
missingData = is.na(data)

omitColumns = which(colSums(missingData) > 19000)

data = data[, -omitColumns]

dim(data)
## [1] 19622    53
```

As you can see, only 53 predictor variables (plus classe) remain in the data set. Next we check that the resulting data frame has no missing values with:

```{r}
table(complete.cases(data))
## 
##  TRUE 
## 19622
```

All of the remaining predictor variables are of numeric type:

```{r}
table(sapply(data[1,], class))
## 
##  factor integer numeric 
##       1      25      27
```


#### Data Splitting and Discussion of Preprocessing.

Following the most commom practice in Machine Learning, I split our data into a training data set (75% of the total cases) and a testing data set (with the remaining cases; the latter should not be confused with the data in the pml-testing.csv file). This will allow me to estimate the out of sample error of our predictor. I use the caret package for this purpose, and begin by setting the seed to ensure reproducibility.

```{r}
set.seed(2014)
library(caret)
## Loading required package: lattice
## Loading required package: ggplot2
inTrain <- createDataPartition(y=data$classe, p=0.75, list=FALSE)

training <- data[inTrain,]
dim(training)
## [1] 14718    53
testing <- data[-inTrain,]
dim(testing)
## [1] 4904   53
```


Some remarks are in order, before proceeding to train our predictor:

Since we are going to apply a non-parametric model (random forests), no preprocessing is needed to transform the variables.
The possible use of PCA to further reduce the number of features is discussed in the Notes section below.
Even though the assignment rubric mentions it, Cross Validation is not necessary for such a direct construction of random forests (in short, because the random forest construction already includes enough subsampling). See the discussion in this thread of the R-help mailing list, and Section 8.2 of An Introduction to Statistical Learning (see References below).
Thus, we are ready to continue building the predictor.

Training the Predictor.
We will use the randomForest function (in the randomForest package) to fit the predictor to the training set. In the computer used for this analysis (see the Notes section below for details) the default number of trees (500) gives a reasonable tradeoff between training time and accuracy. In more powerful machines that number can be increased for (slightly) better predictions.

library(randomForest)
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
time1 = proc.time()
(randForest = randomForest(classe~., data=training, ntree = 500))
## 
## Call:
##  randomForest(formula = classe ~ ., data = training, ntree = 500) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 7
## 
##         OOB estimate of  error rate: 0.49%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 4181    4    0    0    0   0.0009558
## B   20 2823    5    0    0   0.0087781
## C    0    7 2559    1    0   0.0031165
## D    0    0   27 2384    1   0.0116086
## E    0    0    3    4 2699   0.0025868
time2 = proc.time()
(time = time2 - time1)
##    user  system elapsed 
##  151.38    0.81  153.99
As the above results show, the resulting predictor has a quite low OOB (out-of-bag) error estimate. The confusion matrix for the training set indicates that the predictor is accurate on that set.

Applying the Model to the Testing Subsample.
After training the predictor we use it on the testing subsample we constructed before, to get an estimate of its out of sample error.

predictionTesting = predict(randForest, newdata = testing)
The error estimate can be obtained with the confusionMatrix function of the caret package:

confusionMatrix(predictionTesting, testing$classe)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1395    7    0    0    0
##          B    0  939    2    0    0
##          C    0    3  851   14    3
##          D    0    0    2  789    1
##          E    0    0    0    1  897
## 
## Overall Statistics
##                                         
##                Accuracy : 0.993         
##                  95% CI : (0.991, 0.995)
##     No Information Rate : 0.284         
##     P-Value [Acc > NIR] : <2e-16        
##                                         
##                   Kappa : 0.991         
##  Mcnemar's Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             1.000    0.989    0.995    0.981    0.996
## Specificity             0.998    0.999    0.995    0.999    1.000
## Pos Pred Value          0.995    0.998    0.977    0.996    0.999
## Neg Pred Value          1.000    0.997    0.999    0.996    0.999
## Prevalence              0.284    0.194    0.174    0.164    0.184
## Detection Rate          0.284    0.191    0.174    0.161    0.183
## Detection Prevalence    0.286    0.192    0.178    0.162    0.183
## Balanced Accuracy       0.999    0.994    0.995    0.990    0.998
Both the accuracy and the Cohen’s kappa indicator of concordance indicate that the predictor seems to have a low out of sample error rate.

Notes.
The inclusion of the time-of-measure related variables (columns 3 to 7) can be considered. However, this only results in a small increase of prediction accuracy and the decission was made to exclude those variables to avoid a possible overfitting of the predictor to the training data.

Preprocessing with principal Components Analysis (PCA) could be used to reduce the number of variables in the predictor, in the hopes of increasing the performance of the predictor. However, keeping the original variables allows for the analysis of the relative variable importance. For example, we can use the varImplot function:

varImpPlot(randForest)
plot of chunk unnamed-chunk-9

While random forests are not easily interpretable predictors, the variable importance analysis offers at least some insight into the model. But if we were to use PCA, even this would be obscured. Therefore, I decided to keep the predictor based in the original variables. Fine tuning of the model performance based on that importance classification could be considered, if the model is to be implemented in a production setting.

R version and System information for this analysis:
Sys.info()[1:2]
##   sysname   release 
## "Windows"   "7 x64"
R.version.string
## [1] "R version 3.1.1 (2014-07-10)"
As an additional prediction test, the predictor constructed here was used for the Prediction part of this Assignment, for the data in the pml-testing.csv file, and 20 out 20 cases were correctly predicted.
References.
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human ’13) . Stuttgart, Germany: ACM SIGCHI, 2013.

Website for the Groupware@LES Human Activity Recognition project.

An Introduction to Statistical Learning, G. James, D. Witten, T. Hastie, R. Tibshirani. Ed. Springer Verlag (2013). ISBN: 978-1-4614-7138-7.

The Elements of Statistical Learning (2nd. Edition, 10th printing), T. Hastie, R. Tibshirani, J. Friedman. Ed. Springer Verlag (2009). ISBN: 978-0-3878-4857-0.